import streamlit as st
import cv2
import torch
import numpy as np
import os
from PIL import Image
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import time
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration

# --- Cáº¤U HÃŒNH TRANG WEB ---
st.set_page_config(
    page_title="So sÃ¡nh Face Recognition Models",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Táº¢I MODEL VÃ€ Dá»® LIá»†U (CACHE Äá»‚ TÄ‚NG Tá»C) ---
@st.cache_resource
def load_all_models():
    """Táº£i táº¥t cáº£ cÃ¡c model AI má»™t láº§n duy nháº¥t."""
    from facenet_pytorch import MTCNN, InceptionResnetV1
    from insightface.app import FaceAnalysis

    print("Äang táº£i models... (Chá»‰ cháº¡y má»™t láº§n)")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    mtcnn_model = MTCNN(keep_all=True, device=device)
    resnetv1_model = InceptionResnetV1(pretrained='vggface2').eval().to(device)
    arcface_model = FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider' if device.type == 'cuda' else 'CPUExecutionProvider'])
    arcface_model.prepare(ctx_id=0 if device.type == 'cuda' else -1)
    
    print("Táº£i models thÃ nh cÃ´ng.")
    return mtcnn_model, resnetv1_model, arcface_model, device

@st.cache_data
def load_known_face_data_from_file(model_name):
    """Táº£i dá»¯ liá»‡u khuÃ´n máº·t Ä‘Ã£ lÆ°u tá»« cÃ¡c file .npy ban Ä‘áº§u."""
    print(f"Äang táº£i dá»¯ liá»‡u gá»‘c cho {model_name}...")
    emb_file = f'known_{model_name}_embeddings.npy'
    name_file = f'known_{model_name}_names.npy'
    if os.path.exists(emb_file) and os.path.exists(name_file):
        embeddings = list(np.load(emb_file, allow_pickle=True))
        names = list(np.load(name_file, allow_pickle=True))
        return embeddings, names
    return [], []

def recognize_face(embedding, known_embeddings, known_names, threshold=0.6):
    if len(known_embeddings) == 0:
        return "Unknown", 0.0
    similarities = cosine_similarity([embedding], known_embeddings)[0]
    max_idx = np.argmax(similarities)
    max_sim = similarities[max_idx]
    return (known_names[max_idx], max_sim) if max_sim >= threshold else ("Unknown", max_sim)

# Táº£i tÃ i nguyÃªn
mtcnn, resnetv1, arcface_app, device = load_all_models()

# --- Sá»¬ Dá»¤NG SESSION STATE Äá»‚ LÆ¯U TRá»® Dá»® LIá»†U ---
if 'initialized' not in st.session_state:
    st.session_state.known_resnetv1_embeddings, st.session_state.known_resnetv1_names = load_known_face_data_from_file("facenet")
    st.session_state.known_arcface_embeddings, st.session_state.known_arcface_names = load_known_face_data_from_file("arcface")
    st.session_state.initialized = True
    st.sidebar.success("Táº¥t cáº£ cÃ¡c model vÃ  dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i.")

# --- Lá»šP Xá»¬ LÃ VIDEO THá»œI GIAN THá»°C CHO STREAMLIT-WEBRTC ---
class VideoTransformer(VideoTransformerBase):
    def __init__(self):
        self.threshold = 0.6

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Xá»­ lÃ½ vá»›i ResnetV1
        boxes, _ = mtcnn.detect(img_rgb)
        if boxes is not None:
            for box in boxes:
                face_tensor = mtcnn.extract(img_rgb, [box], save_path=None).to(device)
                embedding = resnetv1(face_tensor).detach().cpu().numpy()[0]
                name, sim = recognize_face(embedding, st.session_state.known_resnetv1_embeddings, st.session_state.known_resnetv1_names, self.threshold)
                x1, y1, x2, y2 = map(int, box)
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(img, f'R: {name} ({sim:.2f})', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # Xá»­ lÃ½ vá»›i ArcFace
        faces = arcface_app.get(img)
        if len(faces) > 0:
            for face in faces:
                arc_embedding = face.embedding
                name, sim = recognize_face(arc_embedding, st.session_state.known_arcface_embeddings, st.session_state.known_arcface_names, self.threshold)
                x1, y1, x2, y2 = face.bbox.astype(int)
                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
                cv2.putText(img, f'A: {name} ({sim:.2f})', (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

        return img

# --- GIAO DIá»†N THANH BÃŠN (SIDEBAR) ---
with st.sidebar:
    st.title("Computer Vision Project")
    st.header("So sÃ¡nh FaceNet vÃ  ArcFace")
    st.write("**Sinh viÃªn thá»±c hiá»‡n:** ThÃ¡i")
    st.info("Chá»n cÃ¡c tab bÃªn dÆ°á»›i Ä‘á»ƒ xem chi tiáº¿t.")
    
    st.subheader("Sá»‘ ngÆ°á»i trong CSDL:")
    st.write(f"**{len(np.unique(st.session_state.known_resnetv1_names))}** ngÆ°á»i")

# --- Ná»˜I DUNG CHÃNH ---
st.title("Nháº­n diá»‡n khuÃ´n máº·t: So sÃ¡nh ResNetV1 & ArcFace")

tab1, tab2, tab3 = st.tabs([
    "So sÃ¡nh Tá»•ng quan", 
    "Nháº­n diá»‡n thá»i gian thá»±c",
    "Giá»›i thiá»‡u Dá»± Ã¡n"
])

# --- TAB 1: SO SÃNH Tá»”NG QUAN ---
with tab1:
    st.header("So sÃ¡nh Hiá»‡u suáº¥t vÃ  Kiáº¿n trÃºc")
    # (Giá»¯ nguyÃªn ná»™i dung tab 1)
    st.subheader("1. Báº£ng so sÃ¡nh Kiáº¿n trÃºc")
    try:
        df_arch = pd.read_csv("architecture_comparison.csv")
        st.dataframe(df_arch.style.format(precision=2), use_container_width=True)
    except FileNotFoundError:
        st.error("KhÃ´ng tÃ¬m tháº¥y file `architecture_comparison.csv`.")
    st.subheader("2. Báº£ng so sÃ¡nh trÃªn Benchmark")
    try:
        df_benchmark = pd.read_csv("benchmark_comparison.csv")
        st.dataframe(df_benchmark.style.format(precision=2), use_container_width=True)
    except FileNotFoundError:
        st.error("KhÃ´ng tÃ¬m tháº¥y file `benchmark_comparison.csv`.")
    st.divider()
    st.subheader("3. Biá»ƒu Ä‘á»“ So sÃ¡nh Tá»•ng há»£p")
    if os.path.exists("comparison_charts_full.png"):
        st.image("comparison_charts_full.png", caption="Biá»ƒu Ä‘á»“ so sÃ¡nh hiá»‡u suáº¥t, kiáº¿n trÃºc vÃ  benchmark.")
    else:
        st.warning("KhÃ´ng tÃ¬m tháº¥y file 'comparison_charts_full.png'.")

# --- TAB 2: NHáº¬N DIá»†N THá»œI GIAN THá»°C & QUáº¢N LÃ Dá»® LIá»†U ---
with tab2:
    st.header("Nháº­n diá»‡n thá»i gian thá»±c tá»« webcam")
    st.info("Nháº¥n nÃºt 'START' Ä‘á»ƒ báº­t webcam vÃ  xem káº¿t quáº£ nháº­n diá»‡n. Nháº¥n 'STOP' Ä‘á»ƒ dá»«ng.")
    
    webrtc_streamer(
        key="realtime-recognition",
        video_transformer_factory=VideoTransformer,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

    st.divider()

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ThÃªm ngÆ°á»i má»›i")
        add_name = st.text_input("Nháº­p tÃªn:", key="add_name")
        add_uploaded_img = st.file_uploader("Táº£i áº£nh khuÃ´n máº·t", type=["jpg", "jpeg", "png"], key="add_img")
        
        if st.button("â• ThÃªm"):
            if add_uploaded_img and add_name.strip():
                with st.spinner(f"Äang thÃªm {add_name}..."):
                    img = Image.open(add_uploaded_img).convert("RGB")
                    img_array = np.array(img)
                    
                    boxes, _ = mtcnn.detect(img_array)
                    if boxes is not None:
                        face_tensor = mtcnn.extract(img_array, [boxes[0]], save_path=None).to(device)
                        resnetv1_emb = resnetv1(face_tensor).detach().cpu().numpy()[0]
                        st.session_state.known_resnetv1_embeddings.append(resnetv1_emb)
                        st.session_state.known_resnetv1_names.append(add_name.strip())

                        faces = arcface_app.get(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
                        if len(faces) > 0:
                            arc_emb = faces[0].embedding
                            st.session_state.known_arcface_embeddings.append(arc_emb)
                            st.session_state.known_arcface_names.append(add_name.strip())
                            
                            # LÆ°u file lÃªn Ä‘Ä©a (trÃªn server)
                            np.save('known_facenet_embeddings.npy', np.array(st.session_state.known_resnetv1_embeddings))
                            np.save('known_facenet_names.npy', np.array(st.session_state.known_resnetv1_names))
                            np.save('known_arcface_embeddings.npy', np.array(st.session_state.known_arcface_embeddings))
                            np.save('known_arcface_names.npy', np.array(st.session_state.known_arcface_names))
                            
                            st.success(f"ÄÃ£ thÃªm '{add_name.strip()}'.")
                            st.rerun()
                        else:
                            st.warning("ArcFace khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c khuÃ´n máº·t.")
                            st.session_state.known_resnetv1_embeddings.pop()
                            st.session_state.known_resnetv1_names.pop()
                    else:
                        st.warning("KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t.")
            else:
                st.warning("Vui lÃ²ng táº£i áº£nh vÃ  nháº­p tÃªn!")

    with col2:
        st.subheader("XoÃ¡ ngÆ°á»i Ä‘Ã£ Ä‘Äƒng kÃ½")
        if len(st.session_state.known_resnetv1_names) > 0:
            unique_names = sorted(list(np.unique(st.session_state.known_resnetv1_names)))
            to_delete = st.selectbox("Chá»n tÃªn Ä‘á»ƒ xoÃ¡", unique_names, key="delete_name", index=None, placeholder="Chá»n má»™t tÃªn...")
            
            if st.button("âŒ XoÃ¡") and to_delete:
                new_resnet_emb, new_resnet_names = [], []
                new_arcface_emb, new_arcface_names = [], []
                
                for i, name in enumerate(st.session_state.known_resnetv1_names):
                    if name != to_delete:
                        new_resnet_emb.append(st.session_state.known_resnetv1_embeddings[i])
                        new_resnet_names.append(name)
                        new_arcface_emb.append(st.session_state.known_arcface_embeddings[i])
                        new_arcface_names.append(name)
                
                st.session_state.known_resnetv1_embeddings = new_resnet_emb
                st.session_state.known_resnetv1_names = new_resnet_names
                st.session_state.known_arcface_embeddings = new_arcface_emb
                st.session_state.known_arcface_names = new_arcface_names
                
                np.save('known_facenet_embeddings.npy', np.array(new_resnet_emb))
                np.save('known_facenet_names.npy', np.array(new_resnet_names))
                np.save('known_arcface_embeddings.npy', np.array(new_arcface_emb))
                np.save('known_arcface_names.npy', np.array(new_arcface_names))
                
                st.success(f"ÄÃ£ xoÃ¡ táº¥t cáº£ áº£nh cá»§a '{to_delete}'.")
                st.rerun()
        else:
            st.write("ChÆ°a cÃ³ ai trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.")

# --- TAB 3: GIá»šI THIá»†U Dá»° ÃN ---
with tab3:
    st.header("Má»¥c tiÃªu vÃ  PhÆ°Æ¡ng phÃ¡p")
    # (Giá»¯ nguyÃªn ná»™i dung tab 3)
    st.markdown("""
    Dá»± Ã¡n nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n trong khuÃ´n khá»• mÃ´n há»c Thá»‹ giÃ¡c mÃ¡y tÃ­nh, nháº±m má»¥c Ä‘Ã­ch so sÃ¡nh hai mÃ´ hÃ¬nh nháº­n dáº¡ng khuÃ´n máº·t tiÃªn tiáº¿n: **FaceNet (sá»­ dá»¥ng kiáº¿n trÃºc InceptionResnetV1)** vÃ  **ArcFace (sá»­ dá»¥ng mÃ´ hÃ¬nh buffalo_l)**.

    ### PhÆ°Æ¡ng phÃ¡p so sÃ¡nh
    ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hai mÃ´ hÃ¬nh dá»±a trÃªn cÃ¡c tiÃªu chÃ­ sau:
    1.  **Hiá»‡u suáº¥t trÃªn cÃ¡c bá»™ dá»¯ liá»‡u benchmark chuáº©n.**
    2.  **Äáº·c Ä‘iá»ƒm kiáº¿n trÃºc (Sá»‘ tham sá»‘, FLOPs).**
    3.  **Hiá»‡u suáº¥t trong thá»i gian thá»±c (FPS, Äá»™ á»•n Ä‘á»‹nh).**
    4.  **Thá»­ nghiá»‡m Ä‘á»‹nh tÃ­nh qua áº£nh ngÆ°á»i dÃ¹ng táº£i lÃªn vÃ  webcam.**
    
    ToÃ n bá»™ á»©ng dá»¥ng demo nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng **Streamlit**.
    """)
