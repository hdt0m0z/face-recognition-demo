import streamlit as st
import cv2
import torch
import numpy as np
import os
from PIL import Image
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import time
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration
import tempfile
import io

# --- Cáº¤U HÃŒNH TRANG WEB ---
st.set_page_config(
    page_title="So sÃ¡nh Face Recognition Models",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Táº¢I MODEL VÃ€ Dá»® LIá»†U (CACHE Äá»‚ TÄ‚NG Tá»C) ---
@st.cache_resource
def load_all_models():
    """Táº£i táº¥t cáº£ cÃ¡c model AI má»™t láº§n duy nháº¥t."""
    from facenet_pytorch import MTCNN, InceptionResnetV1
    from insightface.app import FaceAnalysis

    print("Äang táº£i models... (Chá»‰ cháº¡y má»™t láº§n)")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    mtcnn_model = MTCNN(keep_all=True, device=device)
    resnetv1_model = InceptionResnetV1(pretrained='vggface2').eval().to(device)
    arcface_model = FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider' if device.type == 'cuda' else 'CPUExecutionProvider'])
    arcface_model.prepare(ctx_id=0 if device.type == 'cuda' else -1)
    
    print("Táº£i models thÃ nh cÃ´ng.")
    return mtcnn_model, resnetv1_model, arcface_model, device

@st.cache_data
def load_known_face_data_from_file(model_name):
    """Táº£i dá»¯ liá»‡u khuÃ´n máº·t Ä‘Ã£ lÆ°u tá»« cÃ¡c file .npy ban Ä‘áº§u."""
    print(f"Äang táº£i dá»¯ liá»‡u gá»‘c cho {model_name}...")
    emb_file = f'known_{model_name}_embeddings.npy'
    name_file = f'known_{model_name}_names.npy'
    if os.path.exists(emb_file) and os.path.exists(name_file):
        embeddings = list(np.load(emb_file, allow_pickle=True))
        names = list(np.load(name_file, allow_pickle=True))
        return embeddings, names
    return [], []

def recognize_face(embedding, known_embeddings, known_names, threshold=0.6):
    if len(known_embeddings) == 0:
        return "Unknown", 0.0
    similarities = cosine_similarity([embedding], known_embeddings)[0]
    max_idx = np.argmax(similarities)
    max_sim = similarities[max_idx]
    return (known_names[max_idx], max_sim) if max_sim >= threshold else ("Unknown", max_sim)

# Táº£i tÃ i nguyÃªn
mtcnn, resnetv1, arcface_app, device = load_all_models()

# --- Sá»¬ Dá»¤NG SESSION STATE Äá»‚ LÆ¯U TRá»® Dá»® LIá»†U ---
if 'initialized' not in st.session_state:
    st.session_state.known_resnetv1_embeddings, st.session_state.known_resnetv1_names = load_known_face_data_from_file("facenet")
    st.session_state.known_arcface_embeddings, st.session_state.known_arcface_names = load_known_face_data_from_file("arcface")
    st.session_state.initialized = True
    st.sidebar.success("Táº¥t cáº£ cÃ¡c model vÃ  dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i.")

# --- Lá»šP Xá»¬ LÃ VIDEO THá»œI GIAN THá»°C CHO STREAMLIT-WEBRTC ---
class VideoTransformer(VideoTransformerBase):
    def __init__(self):
        self.threshold = 0.6

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Xá»­ lÃ½ vá»›i ResnetV1
        boxes, _ = mtcnn.detect(img_rgb)
        if boxes is not None:
            for box in boxes:
                face_tensor = mtcnn.extract(img_rgb, [box], save_path=None).to(device)
                embedding = resnetv1(face_tensor).detach().cpu().numpy()[0]
                name, sim = recognize_face(embedding, st.session_state.known_resnetv1_embeddings, st.session_state.known_resnetv1_names, self.threshold)
                x1, y1, x2, y2 = map(int, box)
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(img, f'R: {name} ({sim:.2f})', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # Xá»­ lÃ½ vá»›i ArcFace
        faces = arcface_app.get(img)
        if len(faces) > 0:
            for face in faces:
                arc_embedding = face.embedding
                name, sim = recognize_face(arc_embedding, st.session_state.known_arcface_embeddings, st.session_state.known_arcface_names, self.threshold)
                x1, y1, x2, y2 = face.bbox.astype(int)
                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
                cv2.putText(img, f'A: {name} ({sim:.2f})', (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

        return img

# --- GIAO DIá»†N THANH BÃŠN (SIDEBAR) ---
with st.sidebar:
    st.title("Computer Vision Project")
    st.header("So sÃ¡nh FaceNet vÃ  ArcFace")
    st.write("**Sinh viÃªn thá»±c hiá»‡n:** ThÃ¡i")
    st.info("Chá»n cÃ¡c tab bÃªn dÆ°á»›i Ä‘á»ƒ xem chi tiáº¿t.")
    
    st.subheader("Sá»‘ ngÆ°á»i trong CSDL:")
    st.write(f"**{len(np.unique(st.session_state.known_resnetv1_names))}** ngÆ°á»i")

# --- Ná»˜I DUNG CHÃNH ---
st.title("Nháº­n diá»‡n khuÃ´n máº·t: So sÃ¡nh ResNetV1 & ArcFace")

tab1, tab2, tab3, tab4 = st.tabs([
    "So sÃ¡nh Tá»•ng quan", 
    "Demo Trá»±c tiáº¿p",
    "Quáº£n lÃ½ Dá»¯ liá»‡u",
    "Giá»›i thiá»‡u Dá»± Ã¡n"
])

# --- TAB 1: SO SÃNH Tá»”NG QUAN ---
with tab1:
    st.header("So sÃ¡nh Hiá»‡u suáº¥t vÃ  Kiáº¿n trÃºc")
    st.subheader("1. Báº£ng so sÃ¡nh Kiáº¿n trÃºc")
    try:
        df_arch = pd.read_csv("architecture_comparison.csv")
        st.dataframe(df_arch.style.format(precision=2), use_container_width=True)
    except FileNotFoundError:
        st.error("KhÃ´ng tÃ¬m tháº¥y file `architecture_comparison.csv`.")
    st.subheader("2. Báº£ng so sÃ¡nh trÃªn Benchmark")
    try:
        df_benchmark = pd.read_csv("benchmark_comparison.csv")
        st.dataframe(df_benchmark.style.format(precision=2), use_container_width=True)
    except FileNotFoundError:
        st.error("KhÃ´ng tÃ¬m tháº¥y file `benchmark_comparison.csv`.")
    st.divider()
    st.subheader("3. Biá»ƒu Ä‘á»“ So sÃ¡nh Tá»•ng há»£p")
    if os.path.exists("comparison_charts_full.png"):
        st.image("comparison_charts_full.png", caption="Biá»ƒu Ä‘á»“ so sÃ¡nh hiá»‡u suáº¥t, kiáº¿n trÃºc vÃ  benchmark.")
    else:
        st.warning("KhÃ´ng tÃ¬m tháº¥y file 'comparison_charts_full.png'.")

# --- TAB 2: DEMO TRá»°C TIáº¾P ---
with tab2:
    st.header("Thá»­ nghiá»‡m Nháº­n diá»‡n")
    
    demo_tab1, demo_tab2, demo_tab3 = st.tabs(["ğŸ“¸ Webcam Thá»i gian thá»±c", "ğŸ–¼ï¸ PhÃ¢n tÃ­ch áº¢nh", "ğŸ¬ PhÃ¢n tÃ­ch Video"])

    # --- Demo qua Webcam Thá»i gian thá»±c ---
    with demo_tab1:
        st.info("Nháº¥n nÃºt 'START' Ä‘á»ƒ báº­t webcam vÃ  xem káº¿t quáº£ nháº­n diá»‡n theo thá»i gian thá»±c. Nháº¥n 'STOP' Ä‘á»ƒ dá»«ng.")
        webrtc_streamer(
            key="realtime-recognition",
            video_transformer_factory=VideoTransformer,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )

    # --- Demo qua áº¢nh táº£i lÃªn ---
    with demo_tab2:
        st.write("Táº£i lÃªn má»™t bá»©c áº£nh cÃ³ chá»©a khuÃ´n máº·t Ä‘á»ƒ xem káº¿t quáº£ nháº­n diá»‡n tá»« cáº£ hai mÃ´ hÃ¬nh.")
        uploaded_file = st.file_uploader("Chá»n má»™t file áº£nh", type=["jpg", "jpeg", "png"], key="img_uploader")
        if uploaded_file is not None:
            image = Image.open(uploaded_file).convert('RGB')
            frame_rgb = np.array(image)
            frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
            st.image(image, caption='áº¢nh gá»‘c', use_column_width=True)
            with st.spinner('Äang phÃ¢n tÃ­ch...'):
                # (Logic xá»­ lÃ½ áº£nh giá»¯ nguyÃªn)
                boxes, _ = mtcnn.detect(frame_rgb)
                if boxes is not None:
                    for box in boxes:
                        face_tensor = mtcnn.extract(frame_rgb, [box], save_path=None).to(device)
                        embedding = resnetv1(face_tensor).detach().cpu().numpy()[0]
                        name, sim = recognize_face(embedding, st.session_state.known_resnetv1_embeddings, st.session_state.known_resnetv1_names)
                        x1, y1, x2, y2 = map(int, box)
                        cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (0, 255, 0), 2)
                        cv2.putText(frame_bgr, f'R: {name} ({sim:.2f})', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                faces = arcface_app.get(frame_bgr)
                if len(faces) > 0:
                    for face in faces:
                        arc_embedding = face.embedding
                        name, sim = recognize_face(arc_embedding, st.session_state.known_arcface_embeddings, st.session_state.known_arcface_names)
                        x1, y1, x2, y2 = face.bbox.astype(int)
                        cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        cv2.putText(frame_bgr, f'A: {name} ({sim:.2f})', (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
            st.image(frame_bgr, caption='Káº¿t quáº£ Nháº­n diá»‡n', channels="BGR", use_column_width=True)

    # --- Demo qua Video táº£i lÃªn ---
    with demo_tab3:
        st.write("Táº£i lÃªn má»™t file video Ä‘á»ƒ xá»­ lÃ½ vÃ  nháº­n diá»‡n khuÃ´n máº·t trong Ä‘Ã³.")
        uploaded_video = st.file_uploader("Chá»n má»™t file video", type=["mp4", "mov", "avi", "mkv"], key="video_uploader")

        if uploaded_video is not None:
            tfile = tempfile.NamedTemporaryFile(delete=False)
            tfile.write(uploaded_video.read())
            
            cap = cv2.VideoCapture(tfile.name)
            
            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            output_path = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
            out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))
            
            st.success(f"ÄÃ£ táº£i lÃªn video. Báº¯t Ä‘áº§u xá»­ lÃ½ {total_frames} frames...")
            progress_bar = st.progress(0, text="Äang xá»­ lÃ½...")
            
            frame_count = 0
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Ãp dá»¥ng logic nháº­n diá»‡n cho tá»«ng frame
                img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                boxes, _ = mtcnn.detect(img_rgb)
                if boxes is not None:
                    for box in boxes:
                        face_tensor = mtcnn.extract(img_rgb, [box], save_path=None).to(device)
                        embedding = resnetv1(face_tensor).detach().cpu().numpy()[0]
                        name, sim = recognize_face(embedding, st.session_state.known_resnetv1_embeddings, st.session_state.known_resnetv1_names)
                        x1, y1, x2, y2 = map(int, box)
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                        cv2.putText(frame, f'R: {name} ({sim:.2f})', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                faces = arcface_app.get(frame)
                if len(faces) > 0:
                    for face in faces:
                        arc_embedding = face.embedding
                        name, sim = recognize_face(arc_embedding, st.session_state.known_arcface_embeddings, st.session_state.known_arcface_names)
                        x1, y1, x2, y2 = face.bbox.astype(int)
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        cv2.putText(frame, f'A: {name} ({sim:.2f})', (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
                
                out.write(frame)
                frame_count += 1
                progress_bar.progress(frame_count / total_frames, text=f"Äang xá»­ lÃ½ frame {frame_count}/{total_frames}")

            cap.release()
            out.release()
            os.unlink(tfile.name)
            
            progress_bar.empty()
            st.success("Xá»­ lÃ½ video hoÃ n táº¥t!")
            st.video(output_path)
            os.unlink(output_path)


# --- TAB 3: QUáº¢N LÃ Dá»® LIá»†U ---
with tab3:
    st.header("Quáº£n lÃ½ CÆ¡ sá»Ÿ dá»¯ liá»‡u KhuÃ´n máº·t")
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ThÃªm ngÆ°á»i má»›i")
        add_name = st.text_input("Nháº­p tÃªn:", key="add_name_tab3")
        add_uploaded_img = st.file_uploader("Táº£i áº£nh khuÃ´n máº·t", type=["jpg", "jpeg", "png"], key="add_img_tab3")
        if st.button("â• ThÃªm"):
            if add_uploaded_img and add_name.strip():
                # (Logic thÃªm ngÆ°á»i giá»¯ nguyÃªn)
                with st.spinner(f"Äang thÃªm {add_name}..."):
                    img = Image.open(add_uploaded_img).convert("RGB")
                    img_array = np.array(img)
                    boxes, _ = mtcnn.detect(img_array)
                    if boxes is not None:
                        face_tensor = mtcnn.extract(img_array, [boxes[0]], save_path=None).to(device)
                        resnetv1_emb = resnetv1(face_tensor).detach().cpu().numpy()[0]
                        st.session_state.known_resnetv1_embeddings.append(resnetv1_emb)
                        st.session_state.known_resnetv1_names.append(add_name.strip())
                        faces = arcface_app.get(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
                        if len(faces) > 0:
                            arc_emb = faces[0].embedding
                            st.session_state.known_arcface_embeddings.append(arc_emb)
                            st.session_state.known_arcface_names.append(add_name.strip())
                            np.save('known_facenet_embeddings.npy', np.array(st.session_state.known_resnetv1_embeddings))
                            np.save('known_facenet_names.npy', np.array(st.session_state.known_resnetv1_names))
                            np.save('known_arcface_embeddings.npy', np.array(st.session_state.known_arcface_embeddings))
                            np.save('known_arcface_names.npy', np.array(st.session_state.known_arcface_names))
                            st.success(f"ÄÃ£ thÃªm '{add_name.strip()}'.")
                            st.rerun()
                        else:
                            st.warning("ArcFace khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c khuÃ´n máº·t.")
                            st.session_state.known_resnetv1_embeddings.pop()
                            st.session_state.known_resnetv1_names.pop()
                    else:
                        st.warning("KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t.")
            else:
                st.warning("Vui lÃ²ng táº£i áº£nh vÃ  nháº­p tÃªn!")

    with col2:
        st.subheader("XoÃ¡ ngÆ°á»i Ä‘Ã£ Ä‘Äƒng kÃ½")
        if len(st.session_state.known_resnetv1_names) > 0:
            unique_names = sorted(list(np.unique(st.session_state.known_resnetv1_names)))
            to_delete = st.selectbox("Chá»n tÃªn Ä‘á»ƒ xoÃ¡", unique_names, key="delete_name", index=None, placeholder="Chá»n má»™t tÃªn...")
            if st.button("âŒ XoÃ¡") and to_delete:
                # (Logic xÃ³a ngÆ°á»i giá»¯ nguyÃªn)
                new_resnet_emb, new_resnet_names = [], []
                new_arcface_emb, new_arcface_names = [], []
                for i, name in enumerate(st.session_state.known_resnetv1_names):
                    if name != to_delete:
                        new_resnet_emb.append(st.session_state.known_resnetv1_embeddings[i])
                        new_resnet_names.append(name)
                        new_arcface_emb.append(st.session_state.known_arcface_embeddings[i])
                        new_arcface_names.append(name)
                st.session_state.known_resnetv1_embeddings = new_resnet_emb
                st.session_state.known_resnetv1_names = new_resnet_names
                st.session_state.known_arcface_embeddings = new_arcface_emb
                st.session_state.known_arcface_names = new_arcface_names
                np.save('known_facenet_embeddings.npy', np.array(new_resnet_emb))
                np.save('known_facenet_names.npy', np.array(new_resnet_names))
                np.save('known_arcface_embeddings.npy', np.array(new_arcface_emb))
                np.save('known_arcface_names.npy', np.array(new_arcface_names))
                st.success(f"ÄÃ£ xoÃ¡ táº¥t cáº£ áº£nh cá»§a '{to_delete}'.")
                st.rerun()
        else:
            st.write("ChÆ°a cÃ³ ai trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.")

# --- TAB 4: GIá»šI THIá»†U Dá»° ÃN ---
with tab4:
    st.header("Má»¥c tiÃªu vÃ  PhÆ°Æ¡ng phÃ¡p")
    # (Giá»¯ nguyÃªn ná»™i dung tab 3)
    st.markdown("""
    Dá»± Ã¡n nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n trong khuÃ´n khá»• mÃ´n há»c Thá»‹ giÃ¡c mÃ¡y tÃ­nh, nháº±m má»¥c Ä‘Ã­ch so sÃ¡nh hai mÃ´ hÃ¬nh nháº­n dáº¡ng khuÃ´n máº·t tiÃªn tiáº¿n: **FaceNet (sá»­ dá»¥ng kiáº¿n trÃºc InceptionResnetV1)** vÃ  **ArcFace (sá»­ dá»¥ng mÃ´ hÃ¬nh buffalo_l)**.

    ### PhÆ°Æ¡ng phÃ¡p so sÃ¡nh
    ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hai mÃ´ hÃ¬nh dá»±a trÃªn cÃ¡c tiÃªu chÃ­ sau:
    1.  **Hiá»‡u suáº¥t trÃªn cÃ¡c bá»™ dá»¯ liá»‡u benchmark chuáº©n.**
    2.  **Äáº·c Ä‘iá»ƒm kiáº¿n trÃºc (Sá»‘ tham sá»‘, FLOPs).**
    3.  **Hiá»‡u suáº¥t trong thá»i gian thá»±c (FPS, Äá»™ á»•n Ä‘á»‹nh).**
    4.  **Thá»­ nghiá»‡m Ä‘á»‹nh tÃ­nh qua áº£nh ngÆ°á»i dÃ¹ng táº£i lÃªn vÃ  webcam.**
    
    ToÃ n bá»™ á»©ng dá»¥ng demo nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng **Streamlit**.
    """)
